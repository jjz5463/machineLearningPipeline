{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "13cb9a3348a71800ba8c8faf5d6afcb072a02240"
   },
   "source": [
    "# MNIST dataset: a starting-point notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e1b04676e29037b745f456661e81f668971d266f"
   },
   "source": [
    "In this notebook we will classify examples from the MNIST hand-digit dataset according to different classification methods. The accuracy, precision and recall for each classification method will be determined.\n",
    "\n",
    "We will use here:\n",
    "- Logistic regression (\"by hand\" )\n",
    "- Random Forest\n",
    "- Naive Bayes\n",
    "- Support Vector Machines\n",
    "\n",
    "Finally we briefly present the result of the principal compnent analysis (PCA), again adopting a \"by-hand\" aproach.\n",
    "\n",
    "This notebook might be useful to beginners in ML with Python, but with basic ML knowledge (e.g. linear, polynomial, logistic regression; gradient descent etc.).\n",
    "Also, optimization techniques are beyond the scope of his notebook, and we mainly use classifier from sklearn with standard parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "79db4a212560d008b44b11d5a3637ffe64b84fdf"
   },
   "source": [
    "# Part 1: Import libraries and data + some little EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fashion-mnist_test.csv', 't10k-labels-idx1-ubyte']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "f9cc8b5670dda21ce627d4ef5d0d351c24eacc19"
   },
   "outputs": [],
   "source": [
    "#Importing the data as pandas dataframe. We won't use the test.csv file, as we are\n",
    "#concerned with supervised learning here. We rather divide train.csv into train and test set\n",
    "#each example then having its own target value known. \n",
    "\n",
    "train = pd.read_csv('./input/train.csv')\n",
    "#test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fff63a5151e4b103caf9da1b9a5b761348ca2a5f"
   },
   "source": [
    "Let us have a look to the \"train\" data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "49a34cf8079cfe33d31ac69f68a052f9a35bde36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "b8de453da7bd2fcc89b6a58b761d95d374f09e59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "61be39b83a41e939a9709c7f49e29fa6c169dec6"
   },
   "source": [
    "We see it is a $n \\times m$ matrix, with $n = 42000$ examples (images). Note that the first column 'label' denotes the independent variable column, i.e. the true digit corresponding to the image. \n",
    "\n",
    "Each images is then encoded in a $m = 785-1 = 784$ feature vector, representing the intensity of the pixel. Each element of the vector contains an integer encoding the intensity of a pixel. In other words the original image is decomposed in a $28 \\times 28$ pixel grid, which is reshaped to be represented as a $ 28 \\times 28=784$ column vector.\n",
    "\n",
    "Let us see below the visual represetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "9f845c8072e8be9af21ce270e2b7925dd7babf23"
   },
   "outputs": [],
   "source": [
    "# We select 5 random examples (rows) from the train dataset\n",
    "random_indexes = random.sample(range(train.shape[0]),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "19fb10452dd1508f1bc02d3306522e97ba28b5a4"
   },
   "outputs": [],
   "source": [
    "#The original images are obtained by reshaping the rowos\n",
    "original_images = [np.array(train.iloc[element,1:]).reshape(28,28) for element in random_indexes]\n",
    "\n",
    "#The 784-dimensional array form is instead\n",
    "array_representation = [np.array(train.iloc[element,1:]) for element in random_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "96a02d4a57389e34e06d35eaf7ec741a62e2f3d8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing the orginal images\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5)\n",
    "\n",
    "i=0\n",
    "for ax in axes:\n",
    "    ax.imshow(original_images[i], cmap ='gist_gray')\n",
    "    i +=1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "1e567a189e05448e6e489f08b82a8f8bf0d683e9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing their 784-dimensional array form\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5)\n",
    "\n",
    "i=0\n",
    "for ax in axes:\n",
    "    ax.imshow(array_representation[0].reshape(784,1), aspect = 0.02,  cmap='gist_gray')\n",
    "    i +=1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7d9d45d2d0d910d5a7c89089048ff6283a09a213"
   },
   "source": [
    "Let us have a look of the general statistical properties of the matrix 'train'. Many pixels have intensity 0, as it is expected: those correspond to the regions at border of the paper where the digit is originally drawn, which are less likely to be filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "5e12d51142301e35d0ba54413d2d0c4f00ac8c0e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2159763b099bbc43705578f27f1353e74ccabbf7"
   },
   "source": [
    "The most likely pixel to contain part of the hand-written digit is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "8ff7206a0abd5d0e6a92382b3e3bab8c8a0fa6f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pixel407'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe().loc['mean'].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ae7a0a0a0ce7f615dffab6844b8823a86a4fe3d"
   },
   "source": [
    "That is, this guy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "12e4d8171384b0313b75d6311b31d4a4d5a4ca13"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD8CAYAAABJsn7AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAZEklEQVR4nO3dfbQdVXnH8e+PJAQiLyGhpGmCvFgQbG0FbynWtgLxXUtYq6VS25paalpaQWkVQlmrrK5WGtQW7YvWK0hjVRACBdRKxQi6+mIAESQYBAqGXAigDSCWqoT79I/Ztz3reu+ZOXNm7pwZfp+1Zt05M2f27Dvn5Lk7e/Z+RhGBmZnNvd2aroCZ2bOVA7CZWUMcgM3MGuIAbGbWEAdgM7OGOACbmTXEAdjMbBaSPiLpUUlberYtkXS9pHvSz/3Sdkn6a0n3SvqapKPzyncANjOb3T8Ar562bR2wKSIOAzal1wCvAQ5Ly1rgg3mFOwCbmc0iIr4E7Jy2eTWwIa1vAE7q2f7RyHwZWCxpeb/y51dZ2ZlI8lQ7MyskIlRFMUXfKOl3yVqrU8YjYjznsGURsQMgInZIOiBtXwFs73nfRNq2Y7aCag/AZmajKgXbvIBb1Ex/PPr+McgNwJKOIGtar0iFPQRcGxFby9TQzKxOg+S3kUo1uB+RtDy1fpcDj6btE8CBPe9bSRYvZ9W3D1jS2cBlZJH9JuDmtH6ppHX9jjUza8Lk5GThpaRrgTVpfQ1wTc/2N6XREMcCT0x1VcxG/f5aSLob+ImIeHra9t2BO9NdwJmOW8v/96u8OOeXMTMDqukD3rVrV+Em8Pz58/ueT9KlwHHA/sAjwHnA1cDlwHOBB4CTI2Knsub035KNmngKeHNE3NK3/JwAfBfwqojYNm37QcDnIuL5fX87fBPOzIqrIgA//fTThWPOggULqrjpV1peH/DbgU2S7uH/7+49F/hx4K11VszMrIw25Tjv2wIGkLQbcAzZTTiRdTTfHBHPFDqBW8BmVlAVLeDvf//7hWPOwoULG20B5wbgoU/gAGxmBVURgL/3ve8Vjjl77LHHSHdBmJm1yhCjG+acA7CZdUqb+oAdgM2sUxyAzcwa4gBsZtYQB2Azs4b4JpyZWUPcAjYza4gDsJlZQ9oUgHMfSSTpCEmrJO01bfv05ySZmTUuIgovTcvLB3wGWa7L04Etklb37D6/zoqZmZXRpgCc1wXxFuDFEfFdSQcDGyUdHBHvZ+bHbwA/lA/YzGzOdGkUxLyI+C5ARHxT0nFkQfgg+gTg3ucsORmPmc2lUWjZFpXXB/ywpBdNvUjB+PVk2eFfWGfFzMzK6FIXxJuAXb0bImIX2XOPPlRbrczMShqFwFpU3wAcERN99v1b9dUxMxtOZwKwmVnbdOkmnJlZq7gFbGbWEAdgM7OGOACbmTXEAdjMrCEOwGZmDfEoCDOzhrSpBZybjnI6SR+toyJmZlXozFRkSddO3wQcL2kxQEScWFfFzMzKGIXAWlReF8RK4OvARUCQBeAx4C/7HeR0lGbWlDYFYPWrrKTdgLcBrwXeGRG3SbovIg4tfAKnozSzgiJi1jS3RW3durVwzDnyyCOHPt8w8pLxTAIXSroi/Xwk7xgzsyZ1bhREyop2sqTXAd+pt0pmZuW1qQtioNZsRHwG+ExNdTEzG1pnA7CZ2ahrUwAeeBywmdkoq3IcsKQzJd0paYukSyXtIekQSZsl3SPpk5J2L1tXB2Az65TJycnCSz+SVgBnAGMR8ZPAPOAU4ALgwog4DHgMOLVsXR2AzaxTKp4JNx/YU9J8YBGwAzgB2Jj2bwBOKltXB2Az65RBArCktZJu6VnW9pTzIPBe4AGywPsE8BXg8fRwYoAJYEXZuvomnJl1yiA34SJiHBifaZ+k/YDVwCHA48AVwGtmKmbwWmYcgM2sUyocBfFy4P6I+BaApKuAnwMWS5qfWsErgYfKnsBdEGbWKRX2AT8AHCtpkSQBq8hy49wA/Ep6zxrgmrJ1dQvYzDqlqqnIEbFZ0kbgVmAX8FWy7orPAJdJ+vO07eKy58hLR/mzwNaI+I6kPYF1wNFkfwXOj4gnyp7YzKwOVU7EiIjzgPOmbb4POKaK8vO6ID4CPJXW3w/sSzYG7ingkioqYGZWpc4kZAd26xluMRYRR6f1f5V022wHOR+wmTVlFAJrUXkt4C2S3pzWb5c0BiDpcODp2Q6KiPGIGIuIsYrqaWZWSJtawHkB+HeAl0n6T+AFwH9Iug/4cNpnZjZS2hSA8xKyPwH8lqS9gUPT+yci4pG5qJyZ2aC6mJD9SeD2mutiZja0UWjZFuVxwGbWKQ7AZmYNcQA2M2uIA7CZWUM6dxPOzKwt3AI2M2uIA7CZWUMcgM3MGtKZAJwet3wK8FBEfF7SG8kywm8FxiNi1nwQZmZN6EwAJks5OR9YJGkNsBdwFVlm+GPIssGbmY2MLo2CeGFE/FR6JPODwI9FxDOSPkafqclOR2lmTelSC3i31A3xHGARWUL2ncBCYMFsB/U+aVRSe66GmbVelwLwxcBdwDzgXOCKlI7yWOCymutmZjawzgTgiLhQ0ifT+kOSPkr2qOYPR8RNc1FBM7NBdCYAQxZ4e9YfBzbWWiMzsyF0KgCbmbVJl0ZBmJm1ilvAZmYNcQA2M2uIA7CZWUMcgM3MGuKbcGZmDXEL2MysIQ7AZmYNcQA2M2uIA7CZWUM6E4Al7QucA5wE/Eja/ChwDbA+5YaY6TjnAzazRrRpFMRuOfsvBx4DjouIpRGxFDg+bbtitoMiYjwixiJirLqqmpnli4jCS9PyAvDBEXFBRDw8tSEiHo6IC4Dn1ls1M7PBVRmAJS2WtFHSXZK2SnqJpCWSrpd0T/q5X9m65gXgbZLOkrSsp0LLJJ0NbC97UjOzulTcAn4/cF1EHAH8NNkDidcBmyLiMGBTel1KXgB+A7AU+KKknZJ2AjcCS4CTy57UzKwuVQVgSfsAv0j2ZCAi4gfpvtdqYEN62waye2Sl9A3AEfFYRJwdEUdExJK0HBkRZw9zUjOzukxOThZeJK2VdEvP0jt44FDgW8Alkr4q6SJJzwGWRcQOgPTzgLJ1zWsB9/OnQxxrZlaLQVrAvQMG0jLeU9R84GjggxFxFPDfDNHdMJO8YWhfm20XsGyWfWZmjalwdMMEMBERm9PrjWQB+BFJyyNih6TlZENzS8mbiLEMeBXZsLNeAv697EnNzOpSVQCOiIclbZf0/Ij4BrAK+Hpa1gDr089ryp4jLwB/GtgrIm6bvkPSjWVPamZWl4rH954OfFzS7sB9wJvJum4vl3Qq8ABDDEjIeyz9qX32vbHsSc3M6lJlAE6Nz5kmlK2qonzngjCzTmnTVGQHYDPrlFGYYlyUA7CZdYoDsJlZQ571AdjpKM2sKW0KwH1nwknaR9JfSPpHSW+ctu8Dsx3ndJRm1pQupaO8hGzSxZXAKZKulLQw7Tu21pqZmZUwSC6IpuV1QTwvIn45rV8t6VzgC5JOrLleZmaljELLtqi8ALxQ0m4RMQkQEe+SNAF8Cdir9tqZmQ2oTQE4rwviU8AJvRsiYgPwR8AP6qqUmVlZbeoDzpuKfNYs26+TdH49VTIzK28UAmtRzgdsZp3SmZtwzgdsZm3Tphaw8wGbWad0KQA7H7CZtUpnArDzAZtZ23QmAJs1qeg/JEk118TaxAHYzKwhozC6oSgHYDPrlE63gCUdEBGlH8NsZlanzgRgSUumbwJuknQUoIjYOctxzgdsZo3oTAAGvg1sm7ZtBXArEMChMx0UEePAOICk9lwNM2u9LgXgs4CXA++MiDsAJN0fEYfUXjMzsxI6E4Aj4r2SLgMulLQdOI+s5WtWOw8vszI6NQoiIiaAkyX9EnA9sKj2WpmZldSmFnDhbGgR8SngeLIuCSS9ua5KmZmV1aZ8wAOlo4yI/4mILeml01Ga2chpUwB2Okoz65RRCKxFOR2lmXVKl27COR2lmbVKZ1rATkdpZm3TmQBsZtY2DsBmZg1xADYza4gDsJlZQ9o0CmKgiRgAkpYWeM9aSbdIuqVctczMyql6IoakeZK+KunT6fUhkjZLukfSJyXtXraufQOwpPWS9k/rY5LuAzZL2ibpZbMdFxHjETEWEWNlK2ZmVkYNM+HeBmzteX0BcGFEHEY2R2LW0WJ58lrAr4uIb6f19wBviIgfB14B/GXZk5qZ1aXKACxpJfA64KL0WsAJwMb0lg3ASWXrmheAF0ia6ifeMyJuBoiIu4GFZU9qZlaXQQJwb3dpWqY/yed9ZHnRpzqWlwKPR8Su9HqC7CEVpeTdhPs74J8lrQeuk/Q+4CpgFfBDs+PMzJo2yCiI3qf3TCfp9cCjEfEVScdNbZ6pmEHrOCVvJtzfSLoDOA04PL3/cOBq4M/KntTMrC4VjoJ4KXCipNcCewD7kLWIF0uan1rBK4GHyp6gSEL2G4Ebp29P+YAvKXtiM7M6VDUOOCLOAc4BSC3gd0TEr0u6AvgV4DJgDXBN2XMMPAyth/MBm9nImYN8wGcDfyjpXrI+4YvLFuR8wGbWKXXMhOvtCYiI+4BjqijX+YDNrFO6NBXZ+YDNrFXaNBXZ+YDNrFO61AI2M2sVB2Azs4Y4AJuZNcQB2MysIW0KwHnpKMck3SDpY5IOlHS9pCck3SzpqD7HOR+wmTVicnKy8NK0vBbwB4DzgMVk437PjIhXSFqV9r1kpoN6E1xIas+fIzNrvc60gIEFEfHZiLgUiIjYSLayiSw5hZnZSJmDqciVyWsBf0/SK4F9gZB0UkRcnZ6G8Uz91TMzG8woBNai8gLw7wHvJktG/CrgNEn/ADwIvKXeqpmZDa4zATgibicLvFPelpapdJTOB2FmI2UUbq4V5XSUZtYpnekDdjpKM2ubUQisRTkdpZl1SpcCsNNRmlmrdCYAOx2lmbVNZwKwmVnbtGkUhAOwmXWKW8BmZg1xADYza0ibAnBeOsp9Ja2XdJek/0rL1rRt8VxV0sysqDZNxMibCXc52Rjg4yJiaUQsBY5P266Y7SDnAzazprQpAKtfJSR9IyKeP+i+ae9r/rc0s1aICA1bxqpVqwrHnE2bNg19vmHktYC3STpL0v9NO5a0TNLZwPZ6q2ZmNrg2tYDzAvAbgKXAFyU9JmkncCOwBPjVmutmZjawNgXgvJlwj0m6BLge+HJEfHdqn6RXA9fVXD8zs4GMQmAtKm8UxBnANcBbgS2SVvfsPr/OipmZldGZFjDZUy9eHBHflXQwsFHSwRHxfrKMaGZmI6VLU5HnTXU7RMQ3JR1HFoQPwgHYzEbQKLRsi8q7CfewpBdNvUjB+PXA/sAL66yYmVkZXeqCeBOwq3dDROwC3iTpQ7XVysyspFEIrEXljYKY6LPv36qvjpnZcNoUgId5KKeZ2cipqgtC0oGSbkj5b+6UNPVE+CWSrpd0T/q5X9m6OgCbWadMTk4WXnLsAv4oIo4EjgX+QNILgHXApog4DNiUXpfiAGxmnVJVCzgidkTErWn9SWArsAJYDWxIb9sAnFS2rg7AZtYpgwTg3syNaVk7U5lpHsRRwGZgWUTsSOfaARxQtq59b8JJ2gc4B1gJfDYiPtGz7wMR8fuzHLcWmPEXMTOr0yA34SJiHBjv9x5JewFXAm+PiO9I1U2ByGsBX0I24eJK4BRJV0pamPYdO9tBETEeEWMRMVZRPc3MCqlyHLCkBWTx7+MRcVXa/Iik5Wn/cuDRsnXNC8DPi4h1EXF1RJwI3Ap8QdLSsic0M6tThaMgBFwMbI2Iv+rZdS2wJq2vIcuXU0reRIyFknaLiEmAiHiXpAngS8BeZU9qZlaXCnNBvBT4TeAOSbelbX8MrAcul3Qq8ABwctkT5AXgTwEnAJ+f2hARGyQ9AvxN2ZOamdWlqokYEfGvzJ7zZlUV5+jbBRERZwETklaljuip7dcBZ1RRATOzKrUpF0RePuDTyfo3TueH8wG/q86KmZmV0aYAnNcFsRbnAzazFhmFwFqU8wGbWae0KSG78wGbWad0qQvC+YDNrFVGIbAW5XzAZtYpnQnAZmZt4wBsZtaQTgdgSQdEROnkE2ZmdWrTKIi8dJRLpm8CbpJ0FKCI2FlbzczMSuhSC/jbwLZp21aQZUUL4NCZDnI+YDNrSpsCsPpVVtI7gJcD74yIO9K2+yPikMInkNpzNcysUREx9ASvgw46qHDM2bZtW6MTyvKGob1X0mXAhZK2A+eRtXzNzEZSm1rAuTfh0ljgkyX9EnA9sKj2WpmZldSpACzpCLJ+3xvI8gI/L21/dUpLaWY2Mto0CiIvHeUZ9KSjBF4ZEVvS7vNrrpuZ2cC6lAviLTgdpZm1yCgE1qKcjtLMOqVNAdjpKM2sU7rUBeF0lGbWKm26Ced0lGbWKaPQsi3K2dDMrFMcgM3MGuIAbGbWkE4HYElLI+K/6qiMmdmw2hSA82bCrZe0f1ofk3QfsFnSNkkv63PcWkm3SLql4vqamfU1OTlZeGlaXjrKOyLihWn9BuCsiLhZ0uHAJyJiLPcETkdpZgVVkY5y7733LhxznnzyydFNRwkskDQ/jf3dMyJuBoiIuyUtrL96ZmaDaVMXRF4A/jvgnyWtB66T9D7gKmAVcFvdlTMzG1SbAnDfLgiAlP/hNOBwsoC9HbgauCQins49gbsgzKygKrogFi1aVDjmPPXUUyPdBQHwMDAObJ5KzANZPmDA+YDNbKS0qQU8UD5gSat7djsfsJmNnDaNgnA+YDPrlDa1gJ0P2Mw6pU0B2PmAzaxTqswHLOnVkr4h6V5J66qua95EjJXAroh4eIZ9Ly2SktKjIMysqCpGQcybN69wzHnmmWdmPZ+kecDdwCuACeBm4Nci4uvD1nGK8wGbWadUeHPtGODeiLgPQNJlwGqgsgCc1wUxtIjQ9AX43Zm2l1meDWWNct1cVjfKGpW61RVzZlt689akZW1PUSvI5j1MmUjbKlN7AJ7F2vy3uKway3NZLqvu8qquWy0iYjwixnqW8Z7dM/1BqLRLtakAbGY26iaAA3terwQeqvIEDsBmZjO7GThM0iGSdgdOAa6t8gRNPRFjPP8tLqvG8lyWy6q7vKrrNuciYpektwL/AswDPhIRd1Z5DkWLBi2bmXWJuyDMzBriAGxm1pA5DcBVTuuTdKCkGyRtlXSnpLdVUL95kr4q6dNDlrNY0kZJd6X6vWSIss5Mv98WSZdK2mOAYz8i6VFJW3q2LZF0vaR70s/9hizvPen3/Jqkf5K0uGxZPfveISmmnkdYtixJp6fv252S3l22LEkvkvRlSbelsaLHFCxrxu9omc+gT1kDX/+8fzuDXP9+ZZW5/s86McC86WEWsk7s/wQOBXYHbgdeMER5y4Gj0/reZFMGS5eXyvlD4BPAp4csZwPwO2l9d2BxyXJWAPeTPQ4K4HLgtwY4/heBo4EtPdveDaxL6+uAC4Ys75XA/LR+QdHyZiorbT+Q7KbHNmD/Iep1PPB5YGF6fcAQZX0OeE1afy1w4zDf0TKfQZ+yBr7+/f7tDHr9+9Sr1PV/ti1z2QL+v2l9EfEDYGpaXykRsSMibk3rTwJbGWKWSsp78TrgorJlpHL2IftHfHGq2w8i4vEhipwP7ClpPrCIAcYhRsSXgJ3TNq8m+wNB+nnSMOVFxOcie2YgwJfJxkqWrRvAhcBZDDDgfZayTgPWR8T303seHaKsAPZJ6/tS8DPo8x0d+DOYrawy1z/n385A179PWaWu/7PNXAbg2qb1pVzFRwGbhyjmfWRfvGEnkh8KfAu4JHVnXCTpOWUKiogHgfcCDwA7gCci4nND1m9ZROxI5e8ADhiyvF6/DXy27MGSTgQejIjbK6jL4cAvSNos6YuSfmaIst4OvEfSdrLP45xBC5j2HR3qM+jzfR/4+veWNez1n1avKq9/Z81lAK5lWp+kvYArgbdHxHdKlvF64NGI+Mqw9SFrsR4NfDAijgL+m+y/mWXqtR9Za+kQ4MeA50j6jQrqWDlJ5wK7gI+XPH4RcC7wJxVVaT6wH3As8E7gckllcw2cBpwZEQcCZ5L+d1NUFd/RvLLKXP/estKxpa//DPWq8vp31lwG4Mqn9UlaQPahfzwirhqiqJcCJ0r6JlnXyAmSPlayrAlgIiKmWicbyQJyGS8H7o+Ib0X2ANSrgJ8rWdaURyQtB0g/h/6voaQ1ZHmifz1Sh18JzyP7Q3N7+hxWArdK+tGS5U0AV0XmJrL/2RS6qTeDNWTXHuAKsu60Qmb5jpb6DGb7vpe5/jOUVfr6z1KvKq9/Z81lAK50Wl/6a3oxsDUi/mqYikXEORGxMiIOTvX6QkSUamlGljt5u6Tnp02rKJ++7gHgWEmL0u+7iqyPbRjXkgUU0s9rhilM2cNZzwZOjIinypYTEXdExAERcXD6HCbIbu78UC7qgq4GTkh1PJzsZui3S5b1EPCytH4CcE+Rg/p8Rwf+DGYrq8z1n6msste/z+9Y5fXvrrm840d2B/lustEQ5w5Z1s+TdWF8DbgtLa+toI7HMfwoiBcBt6S6XQ3sN0RZfwrcBWwB/pF0V7ngsZeS9R0/TfYP6lRgKbCJLIhsApYMWd69ZH37U5/B35cta9r+b1J8FMRM9dod+Fi6brcCJwxR1s8DXyEbubOZ7DmJpb+jZT6DPmUNfP2L/Nspev371KvU9X+2LZ6KbGbWEM+EMzNriAOwmVlDHIDNzBriAGxm1hAHYDOzhjgAm5k1xAHYzKwh/wvwuP16vx5nFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_im = np.zeros(shape=(28,28))\n",
    "temp_im[407//28, 407%28] = 100\n",
    "\n",
    "sns.heatmap(temp_im, cmap ='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "82228e1975beb11a4a5a7cdcfa2af92d8ff4da4a"
   },
   "source": [
    "#### Question: What's the most frequent digit present in the train set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab1d14f7408cdb00b0c7ee7b9a7e7528761561ac"
   },
   "source": [
    "We see it's number 1. What would we expect? Well, each person who took part to the MNIST experiment had equal probability of writing a digit between 0-9. In practice, some cultural factor might influence their choice. For instance, number one is associated to succes, number 3 to perfection, whereas number 0 might not be so appealing... So if naively one expcets a uniform probability mass distribution for the 0-9 digits, it is not obvious what is going to happen in the infinite-example limit $n -> \\infty$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "29e955454ed38c0203019d1e69d5fb3b9089db08"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.groupby('label').pixel0.count().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "949a788c83b45e5f201dbe8dc97cd4aab6527a80"
   },
   "source": [
    "### Finally we define few functions for later convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "a5599930fc32d934e572e297212985cb222514f7"
   },
   "outputs": [],
   "source": [
    "#Normalizes each pixel column [-1,1], taking into account that some column is completely filed with 0s\n",
    "def feat_normalize(X):\n",
    "    M = X.shape[1]\n",
    "    for i in range(M):\n",
    "        if np.any(X[:,i]) != 0:\n",
    "            min_ = X[:,i].min()\n",
    "            max_ = X[:,i].max()\n",
    "            X[:,i] =(2*X[:,i]-min_-max_)/(max_-min_)\n",
    "            \n",
    "\n",
    "            \n",
    "def append_ones(X):\n",
    "    \n",
    "    s = X.shape[0]\n",
    "    \n",
    "    ones = np.ones(shape=(s,1))\n",
    "    \n",
    "    return np.concatenate((ones, X), axis=1)\n",
    "\n",
    "            \n",
    "#functions to calculate precision, recall and F1 score of a model\n",
    "            \n",
    "\n",
    "def prec_rec_F1(class_rep):\n",
    "    precision = []\n",
    "    recall = []\n",
    "    F1 = []\n",
    "\n",
    "    for i in range(10):\n",
    "        temp = np.zeros(shape=(2,2))\n",
    "        temp[0,0] = class_rep.iloc[i,i]\n",
    "        temp[0,1] = sum(class_rep.iloc[i,:i]) + sum(class_rep.iloc[i,i+1:])\n",
    "        temp[1,0] = sum(class_rep.iloc[:i,i]) + sum(class_rep.iloc[i+1:, i])\n",
    "        temp[1,1] = sum(np.diag(class_rep))- class_rep.iloc[i,i]\n",
    "    \n",
    "        ptemp = temp[0,0]/(temp[0,0]+ temp[0,1])\n",
    "        precision.append([i,ptemp])\n",
    "        rectemp = temp[0,0]/(temp[0,0]+ temp[1,0])\n",
    "        recall.append([i,rectemp])\n",
    "        F1.append([i,2 * ptemp * rectemp /(ptemp+rectemp)])\n",
    "    \n",
    "    return [precision, recall, F1]\n",
    "\n",
    "def create_class_rep(prediction, y_test):\n",
    "    class_rep =np.zeros(shape=(10,10))\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        x = prediction[i]\n",
    "        y = y_test[i]\n",
    "        class_rep[x,y] +=1\n",
    "        \n",
    "    class_rep = pd.DataFrame(class_rep)\n",
    "    return class_rep.applymap(int)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7d83284ef68142cb22a87d6d8e8750b9d1ad02ad"
   },
   "source": [
    "# Part 2: classifying the dataset\n",
    "\n",
    "## First approach: logistic regression by hand\n",
    "\n",
    "We use here the one vs all classification for multiclass problem: \n",
    "- take an example ex\n",
    "- Consider one of the ten classes an example can be classified into (i.e. class = 3)\n",
    "- Get the probabilities for ex to belong to class 3 or not by solving a binary classification model\n",
    "- Repeat for each of the ten classes\n",
    "- Classify ex -> class =... according to the highest obtained probability\n",
    "\n",
    "Let us define few functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "455b7cd4376e1c5506dd000799b7dc5bca9cc707"
   },
   "outputs": [],
   "source": [
    "#Sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "#Cost function of the logistic regression for binary classification, s_i = {0,1} \n",
    "def cost(X, y , theta):\n",
    "    dim = X.shape[0]\n",
    "    s = sigmoid(np.dot(X,theta))\n",
    "    tot = -(np.log(s)*y +np.log(1-s)*(1-y))\n",
    "    return 1/dim *sum(tot)[0]\n",
    "    \n",
    "#Gradient of the cost function with respect to the parameters theta. To be used in gradient descent below\n",
    "def grad_cost(X, y, theta):\n",
    "    \n",
    "    dim = X.shape[0]\n",
    "    pred = sigmoid(np.dot(X,theta))\n",
    "    c1 = 1/dim * np.transpose(pred-y)\n",
    "    return np.transpose(np.dot(c1,X))\n",
    "\n",
    "#Gradient descent to get the parameter theta\n",
    "def grad_descent(X, y, theta, learning_par, num_iter):\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        #print cost(X,y,theta) to check the cost is monotonically decreasing at each iteration\n",
    "        theta = theta - learning_par*grad_cost(X,y,theta)\n",
    "        \n",
    "    return theta\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "c5a05cc048625b6442b988830876f36e4d50b021"
   },
   "outputs": [],
   "source": [
    "#Dividing the training set in train and test set\n",
    "\n",
    "y = train.iloc[:,0]\n",
    "X = train.iloc[:,1:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = 101)\n",
    "\n",
    "#Normalizing the train and test sets\n",
    "X_train = np.array(X_train)\n",
    "feat_normalize(X_train)\n",
    "X_train = append_ones(X_train)\n",
    "\n",
    "\n",
    "#Appending the bias column to the train and test matrices\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "feat_normalize(X_test)\n",
    "X_test = append_ones(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21b74086b0b6a253d2776b288e053a80ae25dd50"
   },
   "source": [
    "Now we can apply the on vs all classification. For each category 0-9 we get the list of target indexes and train the model to classfify whether an example belongs to that category or not, with the respective probability.\n",
    "\n",
    "Each binary classification is trained by minimizing the cost function via gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "354a94cb3d79593f56e867dfc5972daddd166a0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: done!\n",
      "1: done!\n",
      "2: done!\n",
      "3: done!\n",
      "4: done!\n",
      "5: done!\n",
      "6: done!\n",
      "7: done!\n",
      "8: done!\n",
      "9: done!\n"
     ]
    }
   ],
   "source": [
    "#Create the vector of target lables for each digit 0-9\n",
    "y_target = []\n",
    "for i in range(10):\n",
    "    y_target.append(y_train.apply(lambda x: 1 if x == i else 0))\n",
    "    \n",
    "#Initialize the list of training parameters (784+1 (bias) for each digit)\n",
    "theta=[]\n",
    "\n",
    "#Gradient descent to train the model\n",
    "for i in range(10):\n",
    "    ytemp = np.array(y_target[i])\n",
    "    ytemp = ytemp.reshape(y_train.shape[0],1)\n",
    "\n",
    "    thetatemp = np.zeros(shape=(X_train.shape[1],1))\n",
    "\n",
    "    alpha = 0.03\n",
    "    n_iter = 100\n",
    "\n",
    "    thetatemp = grad_descent(X_train,ytemp,thetatemp,alpha,n_iter)\n",
    "    theta.append(thetatemp)\n",
    "    print('{}: done!'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1226a24cd154b0961ca87bbe72fb9ef39d446161"
   },
   "source": [
    "Great, we're all set! We have determined a form for 10 785-dimensional vectors theta[i] which we use to classify new examples. For instance, theta[0] and theta[1] are found as the following (in image form):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "114fcc526eb30442ed8ed71150dd38e1f359a32b"
   },
   "outputs": [],
   "source": [
    "plt.imshow(theta[0][1:].reshape(28,28), cmap='gist_gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ea6cd0bbb5e835eb67140e51620d6f603ad7828a"
   },
   "outputs": [],
   "source": [
    "plt.imshow(theta[1][1:].reshape(28,28), cmap='gist_gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d9963fbb8b321bce20dbf416eab891f076960f59"
   },
   "source": [
    "Classification is nothing but measuring the overlap of new examples with those \"templates\" theta. This overlap is then passed to the sigmoid function, which in turns yields an output between 1 (perfect overlap) and 0 (no overlap at all). So the larger the overlap of a new unseen example with one of those templates, the larger the probability the example corresponds to the digit the tempalte is representative of.\n",
    "\n",
    "#### Let us predict new observation now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "94bbe55213a1d9a7379f3265385ab5aa7588793f"
   },
   "outputs": [],
   "source": [
    "result = [sigmoid(np.dot(X_test,theta[i])) for i in range(10)]\n",
    "result = np.transpose(np.array(result)).reshape(X_test.shape[0],10)\n",
    "\n",
    "prediction = (np.array([element.argmax() for element in result])).reshape(X_test.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e61a45474b5a68db98fd47e5b02a20310b036851"
   },
   "source": [
    "We can now test the accuracy of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7b60c3c16e1854b775b271f47b9e1124e28345d"
   },
   "outputs": [],
   "source": [
    "#testing accuracy of the prediction\n",
    "y_test = np.array(y_test)\n",
    "y_test = y_test.reshape(y_test.shape[0],1)\n",
    "\n",
    "\n",
    "accuracy = sum(prediction == y_test)[0]/(y_test.shape[0])\n",
    "print('Accuracy is: {}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f74f4d2585b076ab1b8fba4e46ab3021fbfe05d9"
   },
   "source": [
    " We find an accuracy of ~82%, which can be improved by tuning the number of iterations and the learning parameter in the gradient descent loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "532c75c321b692b08556f285c94eab03f5173dfa"
   },
   "source": [
    "#### We create a classification matrix\n",
    "\n",
    "That is a matrix summarizing the classification for each example:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6283a4f50a4802636708c3a3c9275cbceb339f82"
   },
   "outputs": [],
   "source": [
    "class_rep = create_class_rep(prediction,y_test)\n",
    "class_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb0295810a146f1a079a62f70cbcefa4b5118946"
   },
   "source": [
    "For instance the first row is telling us that out of (1257+0+3+13+4+8+21+0+22+1)=1329 examples containing the digit \"0\", 1257 have been correctly classfied, 0 of them have been classified as \"1\", 3 as \"2\", etc. \n",
    "\n",
    "\n",
    "From the matrix above we can calculate the precision, recall and F1 score of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "468bbf6d551aaf519b9a6f491329f9d50907b987"
   },
   "outputs": [],
   "source": [
    "precision, recall, F1 = prec_rec_F1(class_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef9ed95760648980b759424efbd7e50a65e74e7f"
   },
   "source": [
    "We can plot the obtained result for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d4de5e7bdc6d5db0cdaabf592697f7efa00f3e93"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.xticks(range(10))\n",
    "plt.yticks(1/10*np.array(range(10)))\n",
    "\n",
    "plt.bar(np.transpose(precision)[0],np.transpose(precision)[1], align='edge', width =-0.25)\n",
    "plt.bar(np.transpose(recall)[0],np.transpose(recall)[1],align='center',width = 0.25)\n",
    "plt.bar(np.transpose(F1)[0],np.transpose(F1)[1],align='edge',width =0.25)\n",
    "plt.legend(labels = ('Precision','Recall','F1'))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7d42c3e5519e0d52ecbb413593ef50b9b4f804f9"
   },
   "source": [
    "## Second approach: Random Forest\n",
    "\n",
    "Here we classify the new examples according the Random Forest algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "26ee16a3739023fba877fc42ef9b65e3a0483591"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bba9e8f515ba99f8b9b15a3fb024b5a9262794e4"
   },
   "outputs": [],
   "source": [
    "#Create a forest with n=100 trees and fot to the model\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a14c84396b17d21626b900a1394058618a597bc9"
   },
   "outputs": [],
   "source": [
    "#Predicting new results\n",
    "prediction = forest.predict(X_test)\n",
    "prediction = prediction.reshape(prediction.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "324784dece825fa9076f4c7c4462782766b38826"
   },
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "accuracy = sum(prediction == y_test)[0]/(y_test.shape[0])\n",
    "print('Accuracy is: {}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ec6022fdb1ca98880cca7289f996677e4087a08"
   },
   "outputs": [],
   "source": [
    "#Classification report\n",
    "class_rep = create_class_rep(prediction,y_test)\n",
    "class_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a0684bf490ebb459c0ec844950cc5463e834a89"
   },
   "outputs": [],
   "source": [
    "#And precision, recall, F1\n",
    "\n",
    "precision, recall, F1 = prec_rec_F1(class_rep)\n",
    "\n",
    "plt.xticks(range(10))\n",
    "plt.yticks(1/10*np.array(range(10)))\n",
    "\n",
    "plt.bar(np.transpose(precision)[0],np.transpose(precision)[1], align='edge', width =-0.25)\n",
    "plt.bar(np.transpose(recall)[0],np.transpose(recall)[1],align='center',width = 0.25)\n",
    "plt.bar(np.transpose(F1)[0],np.transpose(F1)[1],align='edge',width =0.25)\n",
    "plt.legend(labels = ('Precision','Recall','F1'))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "48585d1103a9d50f00bff1c918d88510a05ba50f"
   },
   "source": [
    "## Third approach: Naive Bayes\n",
    "\n",
    "We use here the naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ccad561701e0c362fddd3f62a6258b495a53d18a"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e185e739381db1c49e4a2fce12d4d17d8e9f7db0"
   },
   "outputs": [],
   "source": [
    "#Create an instance of the NB algorothm and fit to the training set\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "150907155c2e2dfbaa06e80ab7201baaa8420148"
   },
   "outputs": [],
   "source": [
    "#Predicting new results\n",
    "prediction = classifier.predict(X_test)\n",
    "prediction = prediction.reshape(prediction.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d8340ca021ccc6dad0da8ff4e882e219ecdabd05"
   },
   "outputs": [],
   "source": [
    "accuracy = sum(prediction == y_test)[0]/(y_test.shape[0])\n",
    "print('Accuracy is: {}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "54a8b09c5f7986cbae5c5a1d72539f11797ccfb8"
   },
   "source": [
    "Accuracy is extremely low as compared to what obtained above. It can of course be improved by some optimization technique (beyond the scope of this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "398fb5db6e3ebce3731e6c5d17efc68dd6e8c1b2"
   },
   "outputs": [],
   "source": [
    "#Classification report\n",
    "class_rep = create_class_rep(prediction,y_test)\n",
    "class_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "646d49cd2fb15965fb765ee6b74a8ab2550e38cb"
   },
   "source": [
    "Where is this low accuracy coming from? Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "71dc00441dcebc29083b94f27ca5ed8777d296c1"
   },
   "outputs": [],
   "source": [
    "#Number of examples for each class\n",
    "class_rep['sum'] = class_rep.sum()\n",
    "\n",
    "#correctly classified examples for each class\n",
    "diag = pd.Series([class_rep.iloc[i,i] for i in range(10)])\n",
    "\n",
    "#Misclassification rate\n",
    "class_rep['misclass_rate'] = 1 - diag / class_rep['sum'] \n",
    "\n",
    "class_rep.drop('sum', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "63c81bf626d2b1129ed646c61afd53984c24956e"
   },
   "source": [
    "We see that the most misclassfied example is \"5\" (95% misclassification rate). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f633efc40deb0b3521fafbfae5335a682b62d1d9"
   },
   "outputs": [],
   "source": [
    "#And precision, recall, F1\n",
    "\n",
    "precision, recall, F1 = prec_rec_F1(class_rep)\n",
    "\n",
    "plt.xticks(range(10))\n",
    "plt.yticks(1/10*np.array(range(10)))\n",
    "\n",
    "plt.bar(np.transpose(precision)[0],np.transpose(precision)[1], align='edge', width =-0.25)\n",
    "plt.bar(np.transpose(recall)[0],np.transpose(recall)[1],align='center',width = 0.25)\n",
    "plt.bar(np.transpose(F1)[0],np.transpose(F1)[1],align='edge',width =0.25)\n",
    "plt.legend(labels = ('Precision','Recall','F1'))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a700352a1f4be8aab2126c8ec2a94879a8416691"
   },
   "source": [
    "## Fourth approach: Support Vector Machine\n",
    "\n",
    "Let us now turn to the support vector machine case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ab3a3bb358f90c791ef0c2b5d4c14a86463cd134"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3759c1d5aa5fbd06a0edbcb2b9f5b660ca94d9f"
   },
   "outputs": [],
   "source": [
    "#Create an instance of SVM and cfit to the training set\n",
    "classifier = LinearSVC()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e12ceba91786b3c889975c93d20e0a3406a259a"
   },
   "outputs": [],
   "source": [
    "#Predicting\n",
    "prediction = classifier.predict(X_test)\n",
    "prediction = prediction.reshape(prediction.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e62169ca95213e2ad2b051a04d356abd1a73e8ad"
   },
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "accuracy = sum(prediction == y_test)[0]/(y_test.shape[0])\n",
    "print('Accuracy is: {}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "25d6e7eed9c162c7b0e903468c2279cef306009b"
   },
   "outputs": [],
   "source": [
    "class_rep = create_class_rep(prediction,y_test)\n",
    "class_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b57f2eb003c3c49dd74e4062b2f7f35617ba5309"
   },
   "outputs": [],
   "source": [
    "#And precision, recall, F1\n",
    "\n",
    "precision, recall, F1 = prec_rec_F1(class_rep)\n",
    "\n",
    "plt.xticks(range(10))\n",
    "plt.yticks(1/10*np.array(range(10)))\n",
    "\n",
    "plt.bar(np.transpose(precision)[0],np.transpose(precision)[1], align='edge', width =-0.25)\n",
    "plt.bar(np.transpose(recall)[0],np.transpose(recall)[1],align='center',width = 0.25)\n",
    "plt.bar(np.transpose(F1)[0],np.transpose(F1)[1],align='edge',width =0.25)\n",
    "plt.legend(labels = ('Precision','Recall','F1'))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a17636574963c62dbac0b47f5b442b8f084cfec6"
   },
   "source": [
    "# Part 3 / Appendix: Principal component analysis\n",
    "\n",
    "As we have briefly discussed above, most of the pixels have average value ~0, mainly corresponding to the border areas of the original papers where the digits were drawn. This suggests that the 784+1-dimensional vector of features can be reduced, as to account for the dominant components while neglecting those which are not playing a crucial role in the classification. \n",
    "\n",
    "\n",
    "To achieve that, we use Principal Component Analysis. What we do is basically look for correlation between the pixels. For instance pixels 407 and 380:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "11cedac786f6727345434a08083c98cafad41773"
   },
   "outputs": [],
   "source": [
    "temp_im = np.zeros(shape=(28,28))\n",
    "temp_im[407//28, 407%28] = 100\n",
    "temp_im[380//28, 380%28] = 100\n",
    "\n",
    "sns.heatmap(temp_im, cmap ='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9814a32ac930bf21c3d33facf311c9cdbeb06613"
   },
   "source": [
    "\n",
    "are most likely highly correlated, in that when drawing a digit, one that hits pixel 380 is likely to hit also pixel 407. We show below a by-hand derivation, although a similar approach can be adopted by making use of PCA from sklearn.decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4ea679fad84a8db9b482aced2e750710a219fda7"
   },
   "outputs": [],
   "source": [
    "#Calculating the covariance matrix, its eigenvalues and eigenvectors\n",
    "X_train_trans = np.transpose(X_train)\n",
    "covariance = np.dot(X_train_trans,X_train)\n",
    "eigenval, eigenvec = np.linalg.eig(covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e9fc8f713ee71a26d98ebea9d0dfe2d51578779e"
   },
   "outputs": [],
   "source": [
    "#We pick the first two main eigenvectors. This comes with some advantage concerning visualization.\n",
    "#(note their are sorted in descnding order with respect to their associated eigenvalues).\n",
    "#Note the imaginary part of the components of those vector is zero.\n",
    "#We take the real part just not ot get any error in the following\n",
    "PCA_mat = np.real(eigenvec[:,0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "887a9165ac8e8b092a4b118e1f95f33eb1a6215f"
   },
   "source": [
    "#### What this components actually are?\n",
    "\n",
    "They are linear combinations of the original 784-dimensional vectors. To viusalize them, let's plot a heatmap, where the contribution of each component is encoded in the intensity of the colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bbe9d9c7c9c2bc7fb9d4990098d7552d09713f9c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(PCA_mat, cmap = 'inferno')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56cf5b122488181c5beb247ac471122bc88217f2"
   },
   "source": [
    " Now that we have obtained the rotation matrix PCA_mat, we can project the training set along these two main directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e135f08f1e27c240d8137e5c24e5df1b4cccee50"
   },
   "outputs": [],
   "source": [
    "X_transf = np.dot(X_train, PCA_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0641c95814a61d7aee9e785ad47a6c0edd9a5d86"
   },
   "source": [
    "We can visualize the data. Each colour if a datapoint corresponds to a class. We see it's very hard to distinguish the different clusters. This suggests that by retaining only 2 principal compenents we are losing some substantial amount of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bcd140e4e95512b242455d75bef10a22d9fd40a7"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_transf[:,0],X_transf[:,1], c = y_train, cmap ='plasma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1be91117e32af8ada85bf7dda1cb64a64df8fd19"
   },
   "source": [
    " To verify this, let us run a standard logistic regression classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9575ab0bfd54b47717d6eb90aa1236b9d7fefc22"
   },
   "outputs": [],
   "source": [
    "y_target = []\n",
    "for i in range(10):\n",
    "    y_target.append(y_train.apply(lambda x: 1 if x == i else 0))\n",
    "    \n",
    "#Initialize the list of training parameters (784+1 (bias) for each digit)\n",
    "theta=[]\n",
    "\n",
    "#Gradient descent to train the model\n",
    "for i in range(10):\n",
    "    ytemp = np.array(y_target[i])\n",
    "    ytemp = ytemp.reshape(y_train.shape[0],1)\n",
    "\n",
    "    thetatemp = np.zeros(shape=(X_transf.shape[1],1))\n",
    "\n",
    "    alpha = 0.03\n",
    "    n_iter = 400\n",
    "\n",
    "    thetatemp = grad_descent(X_transf,ytemp,thetatemp,alpha,n_iter)\n",
    "    theta.append(thetatemp)\n",
    "    print('{}: done!'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5df08bd45217839604b518f059aad71c4d1917d9"
   },
   "source": [
    "Transforming the test set as well, and testing the accuracy of the model, we in fact realize the prediction are not optimal...Accuracy ~29%! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4f20c80d8dcc6803f6d4edb22b2fe3177b3988a3"
   },
   "outputs": [],
   "source": [
    "X_test_transf = np.dot(X_test, PCA_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4694fe69e3438533d03cd0a68fe18a41ac0a67d5"
   },
   "outputs": [],
   "source": [
    "result = [sigmoid(np.dot(X_test_transf,theta[i])) for i in range(10)]\n",
    "result = np.transpose(np.array(result)).reshape(X_test.shape[0],10)\n",
    "\n",
    "prediction = (np.array([element.argmax() for element in result])).reshape(X_test_transf.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2589de5e5125724f935cefb1b590c305bf253f5"
   },
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)\n",
    "y_test = y_test.reshape(y_test.shape[0],1)\n",
    "\n",
    "\n",
    "accuracy = sum(prediction == y_test)[0]/(y_test.shape[0])\n",
    "print('Accuracy is: {}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "672abce690f0528d993a9ba3c35f9cfa6e7b2ba5"
   },
   "source": [
    "How to choose the number of principal component such that a faithful representation of the original dataset is retained? The rule is to preserve '99%' of the variance of the data. A rough way to check this is to compare the cumulative sum of the k-principal eigenvalues against the full $m$ = 785-list of eigenvalues. In particular  we want to check what's the smallest $k$ such that \n",
    " $$ 1- \\frac{\\sum_{k} \\textrm{Eigenvalues}}{\\sum_{m} \\textrm{Eigenvalues}} \\le 0.01 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e29974b8a5dcfb31a093d39fd1bb8ce367412da"
   },
   "outputs": [],
   "source": [
    "for k in range(X_train.shape[1]):\n",
    "    if 1-sum(eigenval[:k])/sum(eigenval) < 0.01:\n",
    "        print('{} principal components needed'.format(k))\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fcac08ad5beeb8ecaebfb67069478ae5dd35b5a5"
   },
   "source": [
    "Can you verify that by using this number of components the accuracy is actually close to that of the full model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
